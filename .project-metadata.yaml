name: DocGenius AI - Generative AI Chatbot
description: |
  Generative AI Chatbot for your Documents powered by Cloudera

author: Suri Nuthalapati
specification_version: 01.0
prototype_version: 1.0
date: "2024-04-25"

environment_variables:
  VECTOR_DB:
    default: "MILVUS"
    description: "Enter 'MILVUS' or 'PINECONE' for your preferred Vector DB. Only 'MILVUS' or 'PINECONE' are valid options. Milvus does not require any additional setup. Pinecone will require you to create an account and generate an API key."
    required: true
  PINECONE_API_KEY:
    default: ""
    description: "Only Required for Pinecone Vector DB: Enter your API Key for Pinecone here. (Shown in API Keys page)"
  PINECONE_ENVIRONMENT:
    default: "gcp-starter"
    description: "Only Required for Pinecone Vector DB: Enter your Pinecone environment here. (Shown in API Keys page)"
  KB_VECTOR_INDEX:
    default: "retail_kb"
    description: "If this is not set now, it will need to be configured for the application to function."
    required: true
  NEXT_PUBLIC_CHATBOT_API_DOMAIN:
    default: "$CDSW_DOMAIN"
    description: "Required for building UI application: Enter the domain for the Chatbot API. This is the same as the CDSW_DOMAIN environment variable."
    required: true
  PROJECT_GIT_BRANCH:
    default: "main"
    description: "Enter the branch name for the git repo. The default is 'main' and can be changed to identify variations for organizations with multiple branches."
  MODEL_DETAILS:
    default: ""
    description: "json string with model details"
    required: true
  HF_TOKEN:
    default: ""
    description: >-
      Blank for Ungated Models
      Provide HuggingFace Token for Gated Models.
    # required: true

runtimes:
  - editor: JupyterLab
    kernel: Python 3.11
    edition: Standard


tasks:
  - type: run_session
    name: Select the Git Branch
    script: session/other/select_git_branch.py
    short_summary: Select the Git Branch
    long_summary: Select the Git Branch. The default is 'main' and can be changed to identify variations for organizations with multiple branches.
    kernel: python3
    cpu: 2
    memory: 8

  - type: run_session
    name: Install Dependencies
    script: session/install-deps/install_general_deps.py
    short_summary: Install Dependencies for your Project
    kernel: python3
    cpu: 4
    memory: 16

  - type: create_job
    name: Populate Milvus Vector DB with documents embeddings
    entity_label: milvus_ingestion
    script: pipeline/load_data/milvus_ingest_kb.py
    arguments: None
    short_summary: Create job to populate Milvus Vector Database with document embeddings. (This is the default Vector DB and will run if "MILVUS" was left or set as the Vector DB.)
    long_summary: Create job to launch Milvus Vector Database locally and insert embeddings for documents. Embeddings are generated by the locally running embeddings model.
    cpu: 4
    memory: 16
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: milvus_ingestion
    short_summary: Populate Milvus Vector DB with document embeddings

  - type: create_job
    name: Populate Pinecone Vector DB with documents embeddings
    entity_label: pinecone_ingestion
    script: pipeline/load_data/pinecone_ingest.py
    arguments: None
    short_summary: Create job to populate Pinecone Vector Database with document embeddings. 
    long_summary: Create job to launch Pinecone Vector Database locally and insert embeddings for documents. Embeddings are generated by the locally running embeddings model.
    cpu: 4
    memory: 16
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: pinecone_ingestion
    short_summary: Populate Pinecone Vector DB with document embeddings (This will only run if you set "PINECONE" as the Vector DB and provided valid parameters.)

  - type: create_model
    name: llama2-7B-chat
    entity_label: llama2_7b_chat
    description: llama2-7B-chat
    short_summary: Deploying a llama-2-7B-chat that runs on CML Model
    default_resources:
      cpu: 4
      memory: 16
      gpu: 1
    default_replication_policy:
      type: fixed
      num_replicas: 1

  - type: build_model
    entity_label: llama2_7b_chat
    comment: First build by the AMP for llama2-7B-chat
    examples:
      - request:
          prompt: What is Cloudera Machine Learning?
          temperature: 1
          max_tokens: 100
          repetition_penalty: 0.5
          context: Cloudera Machine Learning is a platform for machine learning and analytics that runs in the public cloud or on-premises.
          user: genius
    target_file_path: app/chatbot/llama2_7B_chat/model.py
    target_function_name: generate_response
    kernel: python3

  - type: deploy_model
    entity_label: llama2_7b_chat
    cpu: 4
    memory: 32
    gpu: 1

  - type: start_application
    name: API for Chatbot - DocGenuis AI
    subdomain: docgenius-api
    static_subdomain: true
    script: app/main.py
    short_summary: Start API for DocGenuis AI Chatbot 
    long_summary: Start and Publish API for DocGenius AI. Ensure available GPUs for best performance. Remember to enable unauthenticated app access for external access to the UI.
    cpu: 8
    memory: 32
    environment_variables:
      TASK_TYPE: START_APPLICATION
    bypass_authentication: true

  - type: create_job
    name: Build Chatbot UI Code
    entity_label: setup_chatui
    script: chat-ui/setup.py
    arguments: None
    short_summary: Setup Node, NPM, YARN Env Setup and Build Code
    long_summary: Setup Node, NPM, YARN Env Setup and Build Code
    cpu: 2
    memory: 8
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: setup_chatui
    short_summary: Build Chatbot UI Code

  - type: start_application
    name: Frontend UI - DocGenius AI
    subdomain: docgenius-ui
    static_subdomain: true
    script: chat-ui/app.py
    short_summary: Start frontend UI for DocGenuis AI Chatbot 
    long_summary: This task will run Flask app to serve the Chatbot Frontend UI. Remember to enable unauthenticated app access for external access to the UI.
    cpu: 2
    memory: 8
    environment_variables:
      TASK_TYPE: START_APPLICATION
    bypass_authentication: true

  - type: run_session
    name: Configure some features and flags via cmlapi after deployment
    script: session/cmlapi/apply_fix_conf.py
    short_summary: Configure some features and flags via cmlapi after deployment
    kernel: python3
    cpu: 2
    memory: 8